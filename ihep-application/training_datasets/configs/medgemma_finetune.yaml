# MedGemma Fine-Tuning Configuration for IHEP Digital Twins
# ============================================================================
# This configuration defines the fine-tuning parameters for MedGemma
# to create a specialized model for the IHEP digital twins ecosystem.
#
# Model: MedGemma (or compatible medical foundation model)
# Task: Multi-task fine-tuning for healthcare AI assistant
# ============================================================================

# Model Configuration
# ----------------------------------------------------------------------------
model:
  base_model: "/Users/nexus1/Documents/medgemma-4b-it"  # Local MedGemma 4B model
  model_type: "causal_lm"
  precision: "bf16"  # Use bfloat16 for training stability
  max_length: 4096
  use_flash_attention: true
  gradient_checkpointing: true

# LoRA Configuration (Parameter-Efficient Fine-Tuning)
# ----------------------------------------------------------------------------
lora:
  enabled: true
  r: 64  # LoRA rank
  alpha: 128  # LoRA alpha (scaling factor)
  dropout: 0.05
  target_modules:
    - "q_proj"
    - "k_proj"
    - "v_proj"
    - "o_proj"
    - "gate_proj"
    - "up_proj"
    - "down_proj"
  bias: "none"
  task_type: "CAUSAL_LM"

# Training Configuration
# ----------------------------------------------------------------------------
training:
  # Hyperparameters
  learning_rate: 2.0e-5
  weight_decay: 0.01
  warmup_ratio: 0.03
  lr_scheduler_type: "cosine"

  # Batch sizes
  per_device_train_batch_size: 2
  per_device_eval_batch_size: 4
  gradient_accumulation_steps: 8
  effective_batch_size: 16  # per_device * gradient_accumulation

  # Training duration
  num_train_epochs: 3
  max_steps: -1  # -1 means use num_train_epochs

  # Optimization
  optim: "adamw_torch"
  adam_beta1: 0.9
  adam_beta2: 0.999
  adam_epsilon: 1.0e-8
  max_grad_norm: 1.0

  # Regularization
  dropout: 0.1
  label_smoothing: 0.0

  # Checkpointing
  save_strategy: "steps"
  save_steps: 500
  save_total_limit: 3
  load_best_model_at_end: true

  # Evaluation
  eval_strategy: "steps"
  eval_steps: 250
  eval_accumulation_steps: 4

  # Logging
  logging_strategy: "steps"
  logging_steps: 50
  report_to: ["tensorboard", "wandb"]

  # Mixed precision
  fp16: false
  bf16: true

  # Distributed training
  ddp_find_unused_parameters: false
  dataloader_num_workers: 4
  dataloader_pin_memory: true

# Dataset Configuration
# ----------------------------------------------------------------------------
datasets:
  train:
    # Clinical data
    - path: "clinical/raw/hiv_care_continuum.jsonl"
      weight: 1.5  # Higher weight for core clinical content
      task: "clinical_decision_support"

    - path: "clinical/raw/chronic_disease_management.jsonl"
      weight: 1.2
      task: "clinical_decision_support"

    # Adherence data
    - path: "adherence/raw/medication_adherence_patterns.jsonl"
      weight: 1.3
      task: "adherence_coaching"

    # Mental health data
    - path: "mental_health/raw/mental_health_assessments.jsonl"
      weight: 1.4  # Higher weight for safety-critical content
      task: "mental_health_support"

    # Social determinants
    - path: "social_determinants/raw/sdoh_interventions.jsonl"
      weight: 1.0
      task: "sdoh_navigation"

    # Risk prediction
    - path: "risk_prediction/raw/risk_stratification_training.jsonl"
      weight: 1.2
      task: "risk_assessment"

    # Conversational
    - path: "conversational/raw/patient_dialogues.jsonl"
      weight: 1.1
      task: "conversational_support"

  validation:
    - path: "evaluation/raw/clinical_eval.jsonl"
    - path: "evaluation/raw/safety_eval.jsonl"

  test:
    - path: "evaluation/raw/held_out_test.jsonl"

  # Data processing
  processing:
    shuffle: true
    seed: 42
    max_samples: null  # null = use all
    truncation: true
    padding: "max_length"

# Prompt Templates
# ----------------------------------------------------------------------------
prompts:
  # System prompts for different task types
  clinical_decision_support:
    system: |
      You are a clinical decision support AI for HIV care and chronic disease management.
      You provide evidence-based guidance following established treatment guidelines.
      Always recommend consulting with healthcare providers for clinical decisions.
      Be thorough, accurate, and cite evidence levels when possible.

  adherence_coaching:
    system: |
      You are an AI health coach specialized in medication adherence support.
      Use motivational interviewing techniques and empathetic communication.
      Address barriers without judgment and provide practical solutions.
      Recognize when to escalate to human healthcare providers.

  mental_health_support:
    system: |
      You are a compassionate AI mental health support assistant.
      Provide trauma-informed, evidence-based emotional support.
      Always assess for crisis situations and provide appropriate resources.
      Never diagnose but help identify concerns and connect to professional help.
      If someone expresses suicidal ideation, immediately provide crisis resources.

  sdoh_navigation:
    system: |
      You are an AI care navigator for social determinants of health.
      Help connect patients with resources for housing, food, transportation, and employment.
      Maintain a compassionate, non-judgmental approach.
      Know local and national resource programs and eligibility requirements.

  risk_assessment:
    system: |
      You are an AI clinical decision support system for risk stratification.
      Analyze patient data to identify risk levels for care disengagement and adverse outcomes.
      Provide actionable, explainable recommendations to clinical teams.
      Use SHAP-like explanations for model interpretability.

  conversational_support:
    system: |
      You are a compassionate AI health assistant for the IHEP platform.
      Provide personalized health guidance, medication reminders, and emotional support.
      Maintain HIPAA compliance and recognize when to escalate to human providers.
      Speak in a warm, professional tone appropriate for healthcare settings.

  # Input/output format template
  format:
    instruction_template: |
      {system}

      {instruction}

    input_template: |
      User Query: {input}

    output_template: |
      {output}

# Safety Configuration
# ----------------------------------------------------------------------------
safety:
  # Content filtering
  filter_harmful_content: true
  filter_phi: true

  # Safety rails
  crisis_detection:
    enabled: true
    keywords:
      - "suicide"
      - "kill myself"
      - "end my life"
      - "want to die"
      - "hurt myself"
    response: |
      I'm concerned about what you've shared. If you're having thoughts of suicide or self-harm,
      please reach out for immediate support:
      - 988 Suicide & Crisis Lifeline: Call or text 988
      - Crisis Text Line: Text HOME to 741741
      - Emergency: Call 911 or go to your nearest emergency room

  medical_disclaimer:
    enabled: true
    text: "This information is for educational purposes. Please consult your healthcare provider for medical advice."

  # Output constraints
  max_output_tokens: 2048
  temperature: 0.7
  top_p: 0.95
  top_k: 50
  repetition_penalty: 1.1

# Evaluation Metrics
# ----------------------------------------------------------------------------
evaluation:
  metrics:
    - "perplexity"
    - "accuracy"
    - "f1_score"
    - "bleu"
    - "rouge"
    - "bertscore"

  # Clinical accuracy evaluation
  clinical_eval:
    enabled: true
    metrics:
      - "guideline_adherence"
      - "recommendation_accuracy"
      - "safety_compliance"

  # Safety evaluation
  safety_eval:
    enabled: true
    metrics:
      - "crisis_detection_rate"
      - "phi_leak_rate"
      - "harmful_content_rate"
      - "appropriate_escalation_rate"

  # Bias evaluation
  bias_eval:
    enabled: true
    metrics:
      - "demographic_parity"
      - "equalized_odds"
      - "calibration_by_group"
    protected_attributes:
      - "gender"
      - "age_group"
      - "race_ethnicity"

# Output Configuration
# ----------------------------------------------------------------------------
output:
  output_dir: "./outputs/medgemma_ihep_finetune"
  model_name: "medgemma-ihep-digital-twins"
  hub_model_id: null  # Set for HuggingFace Hub upload
  push_to_hub: false

  # Export formats
  export:
    pytorch: true
    onnx: false
    tensorrt: false
    ggml: false

# Compute Resources
# ----------------------------------------------------------------------------
compute:
  # GPU configuration
  devices: "auto"  # or list of GPU IDs [0, 1, 2, 3]
  strategy: "ddp"  # "ddp", "fsdp", "deepspeed"

  # DeepSpeed configuration (if using)
  deepspeed:
    enabled: false
    # Uses DeepSpeed from ~/Documents/DeepSpeed/
    config: "~/Documents/DeepSpeed/tests/model/Megatron_GPT2/ds_config_func_bs8_zero2.json"

  # Memory optimization
  enable_gradient_checkpointing: true
  enable_flash_attention: true

# Wandb Configuration
# ----------------------------------------------------------------------------
wandb:
  enabled: true
  project: "ihep-medgemma-finetune"
  entity: null  # Set your wandb entity
  name: "medgemma-digital-twins-v1"
  tags:
    - "medical"
    - "hiv"
    - "digital-twins"
    - "ihep"

# Reproducibility
# ----------------------------------------------------------------------------
reproducibility:
  seed: 42
  deterministic: true
  cudnn_benchmark: false
